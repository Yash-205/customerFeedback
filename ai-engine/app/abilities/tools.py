from langchain_core.tools import tool
from typing import List, Dict

from app.memory.vector.client import VectorDatabase
from app.memory.graph.client import Neo4jClient
from app.processing.aggregator import GlobalAggregator

# Initialize Singletons
vector_db = VectorDatabase()
graph_db = Neo4jClient()
aggregator = GlobalAggregator()
def get_embedding_model():
    import torch
    from sentence_transformers import SentenceTransformer
    global _embedding_model
    if '_embedding_model' not in globals():
        print("â³ Loading embedding model into memory (tools)...")
        torch.set_num_threads(1)
        _embedding_model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')
    return _embedding_model

@tool
def search_vector_memory(query: str) -> str:
    """
    Search for raw feedback chunks using semantic similarity.
    Use this to find specific quotes, evidence, or detailed user stories.
    """
    # 1. Convert text to vector
    model = get_embedding_model()
    query_vector = model.encode([query])[0].tolist()
    
    # 2. Search Qdrant
    results = vector_db.search(query_vector, limit=5)
    
    if not results:
        return "No relevant documents found in vector memory."
        
    return str([r['content'] for r in results])

@tool
def query_graph_memory(cypher_query: str) -> str:
    """
    Execute a Cypher query on the Graph Database.
    Use this to find relationships between Users, Summaries, and Entities.
    Schema: (User)-[:WROTE]->(Summary)-[r:MENTIONS]->(EntityNode)
    EntityNode labels: Issue, Feature, Product, Entity.
    Properties: Node has 'name'. Relationship 'MENTIONS' has 'sentiment'.
    Example: MATCH (s:Summary)-[r:MENTIONS]->(i:Issue) RETURN i.name, r.sentiment, count(i)
    """
    if not graph_db.driver:
        return "Graph DB not connected"
    
    try:
        with graph_db.driver.session() as session:
            result = session.run(cypher_query)
            data = [dict(record) for record in result]
            
            if not data:
                return "No results found for this graph query."
                
            return str(data)
    except Exception as e:
        return f"Graph Query Error: {str(e)}"

@tool
def fetch_global_themes() -> str:
    """
    Retrieve the high-level Global Theme Report generated by RLM.
    Use this to get a broad overview of top issues and trends before diving deep.
    """
    # For now, we run the aggregator on demand. 
    # In prod, this would fetch a pre-computed report from DB.
    return aggregator.run_aggregation()
